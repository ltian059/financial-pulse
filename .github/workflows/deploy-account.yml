name: Deploy Account Service

on:
  push:
    branches: [ master ]
    paths:
      - 'fp-account/**'
      - 'fp-common/**'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - test
          - prod

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      jar-name: ${{steps.build.outputs.jar-name}}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'

      - name: Cache Maven dependencies
        uses: actions/cache@v3
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2

      - name: Build with Maven
        id: build
        run: |
          # First install the parent POM
          mvn clean install -N
          # Then install fp-common
          mvn clean install -pl fp-common -DskipTests
          # Finally build fp-account
          mvn clean package -pl fp-account -DskipTests
          JAR_NAME=$(ls fp-account/target/fp-account-*.jar | head -1 | xargs basename)
          echo "jar-name=$JAR_NAME" >> $GITHUB_OUTPUT
          echo "Built JAR: $JAR_NAME"

      - name: Upload JAR artifact
        uses: actions/upload-artifact@v4
        with:
          name: account-service-jar
          path: fp-account/target/fp-account-*.jar
          retention-days: 1

  validate-and-deploy:
    runs-on: ubuntu-latest
    needs: [ build ]
    # The Environment currently deploying to
    environment: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install PyYAML

      - name: Validate configuration templates
        run: |
          echo "üîç Validating configuration templates against workflow variables..."
          python fp-deployment/scripts/validate-env-vars.py account

      - name: Determine Spring Profile
        id: profile
        run: |
          ENV_NAME="${{ github.event.inputs.environment || 'dev' }}"
          SPRING_PROFILE=${ENV_NAME#*-} # Remove 'account-' prefix
          echo "Environment: $ENV_NAME"
          echo "Spring Profile: $SPRING_PROFILE"
          echo "profile=$SPRING_PROFILE" >> $GITHUB_OUTPUT

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts

      - name: Setup SSH key
        run: |
          echo "${{ secrets.EC2_SSH_KEY }}" > /tmp/fp-keypair.pem
          chmod 600 /tmp/fp-keypair.pem

      - name: Create environment variable file.
        run: |
          echo " Creating environment configuration..."
          cat > .env << 'EOF'
          # Application Configuration
          SPRING_PROFILES_ACTIVE=${{ steps.profile.outputs.profile }}
          
          # JWT Configuration
          JWT_SECRET=${{ secrets.JWT_SECRET }}
          
          # AWS Configuration
          AWS_REGION=${{ vars.AWS_REGION }}
          
          # Server port
          SERVER_PORT=8080
          
          # DynamoDB configuration
          DYNAMODB_TABLE_PREFIX=${{ vars.DYNAMODB_TABLE_PREFIX }}
          DYNAMODB_TABLE_SUFFIX=${{ vars.DYNAMODB_TABLE_SUFFIX }}
          
          # SQS Configuration
          SQS_EMAIL_QUEUE_URL=${{ vars.SQS_EMAIL_QUEUE_URL }}
          SQS_FOLLOWER_NOTIFICATION_QUEUE_URL=${{ vars.SQS_FOLLOWER_NOTIFICATION_QUEUE_URL }}
          SQS_DEAD_LETTER_QUEUE_URL=${{ vars.SQS_DEAD_LETTER_QUEUE_URL }}
          AWS_SQS_ENABLED=true
          
          EOF
          
          echo " Environment configuration created"
          
          echo "üîç Validating actual environment variables..."
          python fp-deployment/scripts/validate-env-file.py .env


      - name: Upload files to S3
        run: |
          BUCKET_NAME="fp-app-deployments-${{ github.event.inputs.environment || 'dev' }}-${{ vars.AWS_REGION }}"
          JAR_NAME=${{ needs.build.outputs.jar-name }}
          S3_JAR_KEY="account/fp-account.jar"
          S3_ENV_KEY="account/.env"
          # Copy Python scripts from fp-deployment module and make them executable
          START_SCRIPT_NAME="start.py"
          STOP_SCRIPT_NAME="stop.py"
          LOGUTIL_SCRIPT_NAME="logutil.py"
          
          SCRIPT_PATH="fp-deployment/scripts"
          
          echo "üì§ Uploading files to S3..."
          aws s3 cp ./artifacts/account-service-jar/$JAR_NAME s3://$BUCKET_NAME/$S3_JAR_KEY --no-progress
          aws s3 cp .env s3://$BUCKET_NAME/$S3_ENV_KEY --no-progress
          aws s3 cp $SCRIPT_PATH/$START_SCRIPT_NAME s3://$BUCKET_NAME/account/start.py --no-progress
          aws s3 cp $SCRIPT_PATH/$STOP_SCRIPT_NAME s3://$BUCKET_NAME/account/stop.py --no-progress
          aws s3 cp $SCRIPT_PATH/$LOGUTIL_SCRIPT_NAME s3://$BUCKET_NAME/account/logutil.py --no-progress
          echo "‚úÖ All files uploaded to S3"

      - name: Deploy via SSH through EC2 Instance Connect
        run: |
          INSTANCE_ID="${{ vars.EC2_ACCOUNT_INSTANCE_ID }}"
          BUCKET_NAME="fp-app-deployments-${{ github.event.inputs.environment || 'dev' }}-${{ vars.AWS_REGION }}"
          
          echo "üîó Connecting to EC2 instance $INSTANCE_ID via Instance Connect Endpoint"
          
          # SSH with ProxyCommand to use EC2 Instance Connect Endpoint
          ssh -i /tmp/fp-keypair.pem ec2-user@$INSTANCE_ID \
          -o ProxyCommand="aws ec2-instance-connect open-tunnel --instance-id $INSTANCE_ID" \
          -o StrictHostKeyChecking=no \
          -o UserKnownHostsFile=/dev/null \
          << SSH_COMMANDS          
          set -e
          
          echo "=== Financial Pulse Deployment Starting ==="
          sudo chown -R ec2-user:ec2-user /opt/app
          
          cd /opt/app
          
          echo "üì• Downloading from S3..."
          aws s3 cp s3://${BUCKET_NAME}/account/fp-account.jar ./fp-account.jar --no-progress
          aws s3 cp s3://${BUCKET_NAME}/account/.env ./.env --no-progress
          aws s3 cp s3://${BUCKET_NAME}/account/start.py ./ --no-progress
          aws s3 cp s3://${BUCKET_NAME}/account/stop.py ./ --no-progress
          aws s3 cp s3://${BUCKET_NAME}/account/logutil.py ./ --no-progress
          
          echo "üîß Setting permissions..."
          chmod +x start.py stop.py
          chmod 644 .env fp-account.jar
          
          echo " Stopping existing service..."
          python3 stop.py fp-account.jar || true
          
          echo " Starting new service..."
          python3 start.py fp-account.jar
          
          echo " Performing health check..."
          i=1
          while [ \$i -le 10 ]; do
            if curl -f http://localhost:8080/health >/dev/null 2>&1; then
              echo "‚úÖ Health check passed!"
              break
            else
              echo "‚è≥ Health check attempt \$i/10..."
              sleep 6
            fi
            
            if [ \$i -eq 10 ]; then
              echo "‚ùå Health check failed after 10 attempts"
              tail -n 50 /opt/app/app.log
              exit 1
            fi
            i=\$((i + 1))
          done
          
          echo "=== Deployment completed successfully ==="
          SSH_COMMANDS